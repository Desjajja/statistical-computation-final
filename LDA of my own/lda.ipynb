{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('lda': conda)"
  },
  "interpreter": {
   "hash": "651ac778ade725b395fcc36af3c5e8d35726f631ae363959a9f7766aee392b58"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\Desjajja\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.739 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jieba\n",
    "from gensim.models import LdaModel\n",
    "import pandas as pd\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "train = r\"C:\\Users\\Desjajja\\OneDrive - email.ncu.edu.cn\\课程\\统计计算\\期末\\iflytek_public\\train.json\" # 训练集路径\n",
    "\n",
    "\n",
    "with open(train, encoding='utf-8') as f:\n",
    "    sentences = [] # 逐行读取json文件，分词，存入列表\n",
    "\n",
    "    for line in f.readlines():\n",
    "\n",
    "        d = json.loads(line)\n",
    "\n",
    "        label = d['label']\n",
    "\n",
    "        label_des = d['label_des']\n",
    "\n",
    "        sentence = d['sentence']\n",
    "\n",
    "        sentence = sentence.strip()\n",
    "\n",
    "        sentence = \",\".join(sentence.split())\n",
    "\n",
    "        sentences.append(jieba.lcut(sentence))\n",
    "\n",
    "    f.close()"
   ]
  },
  {
   "source": [
    "# Training LDA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(sentences)\n",
    "dictionary.filter_n_most_frequent(200)\n",
    "corpus = [dictionary.doc2bow(text) for text in sentences ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "10个主题的单词分布为：\n\n(0, '0.010*\"商品\" + 0.008*\"优惠券\" + 0.007*\"快递\" + 0.007*\"折扣\" + 0.007*\"购物\" + 0.006*\"优惠\" + 0.006*\"充值\" + 0.006*\"多开\" + 0.005*\"旅行\" + 0.005*\"旅游\"')\n(1, '0.019*\"小说\" + 0.018*\"阅读\" + 0.007*\"公交\" + 0.005*\"★\" + 0.004*\"热门\" + 0.004*\"僵尸\" + 0.003*\"流量\" + 0.003*\"播放\" + 0.003*\"路线\" + 0.003*\"正版\"')\n(2, '0.010*\"跑\" + 0.008*\"胡子\" + 0.005*\"捕鱼\" + 0.005*\"预测\" + 0.004*\"麻将\" + 0.004*\"约会\" + 0.004*\"流量\" + 0.004*\"单机\" + 0.004*\"交友\" + 0.003*\"送\"')\n(3, '0.008*\"手游\" + 0.005*\"开启\" + 0.005*\"技能\" + 0.004*\"直播\" + 0.004*\"聊天\" + 0.004*\"音乐\" + 0.004*\"战斗\" + 0.004*\"交友\" + 0.003*\"萌宠\" + 0.003*\"来电\"')\n(4, '0.006*\"红包\" + 0.005*\"企业\" + 0.005*\"文件\" + 0.005*\"支付\" + 0.004*\"动态\" + 0.004*\"壁纸\" + 0.004*\"通知\" + 0.004*\"客户端\" + 0.004*\"云\" + 0.003*\"设备\"')\n(5, '0.032*\"宝宝\" + 0.017*\";\" + 0.014*\"&\" + 0.010*\"巴士\" + 0.009*\"音乐\" + 0.005*\"故事\" + 0.005*\"妈妈\" + 0.005*\"儿歌\" + 0.005*\"育儿\" + 0.005*\"儿童\"')\n(6, '0.012*\"直播\" + 0.007*\"电视\" + 0.006*\"壁纸\" + 0.005*\"动态\" + 0.005*\"公主\" + 0.005*\"美丽\" + 0.005*\"她\" + 0.004*\"图片\" + 0.004*\"高清\" + 0.004*\"它\"')\n(7, '0.017*\"贷款\" + 0.016*\"借款\" + 0.008*\"借钱\" + 0.008*\"申请\" + 0.007*\"还款\" + 0.007*\"新闻\" + 0.007*\"额度\" + 0.006*\"信用卡\" + 0.006*\"现金\" + 0.006*\"分钟\"')\n(8, '0.021*\"=\" + 0.007*\"＊\" + 0.006*\"记录\" + 0.005*\"运动\" + 0.005*\"宁夏\" + 0.005*\"办事\" + 0.005*\"健康\" + 0.004*\"计算器\" + 0.004*\"社保\" + 0.004*\"健身\"')\n(9, '0.007*\"孩子\" + 0.006*\"英语\" + 0.006*\"学生\" + 0.005*\"课程\" + 0.004*\"考试\" + 0.004*\"儿童\" + 0.003*\"老师\" + 0.003*\"单词\" + 0.003*\"练习\" + 0.003*\"题库\"')\n"
     ]
    }
   ],
   "source": [
    "topic_list = lda.print_topics(10)\n",
    "print(\"10个主题的单词分布为：\\n\")\n",
    "for topic in topic_list:\n",
    "    print(topic)"
   ]
  },
  {
   "source": [
    "# Test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = r\"C:\\Users\\Desjajja\\OneDrive - email.ncu.edu.cn\\课程\\统计计算\\期末\\iflytek_public\\dev.json\"\r\n",
    "\r\n",
    "with open(demo, encoding='utf-8') as f:\r\n",
    "    demo_sentences = [] # 逐行读取json文件，分词，存入列表\r\n",
    "\r\n",
    "    demo_labels = []\r\n",
    "\r\n",
    "    for line in f.readlines():\r\n",
    "\r\n",
    "        d = json.loads(line)\r\n",
    "\r\n",
    "        label = d['label']\r\n",
    "\r\n",
    "        label_des = d['label_des']\r\n",
    "\r\n",
    "        sentence = d['sentence']\r\n",
    "\r\n",
    "        sentence = sentence.strip()\r\n",
    "\r\n",
    "        sentence = \",\".join(sentence.split())\r\n",
    "\r\n",
    "        demo_sentences.append(jieba.lcut(sentence))\r\n",
    "\r\n",
    "        demo_labels.append(label)\r\n",
    "\r\n",
    "f.close()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label id: 110\n\n\nlda result: [(0, 0.4713706), (4, 0.42289895), (5, 0.09384658)]\n\n\nlabel id: 70\n\n\nlda result: [(0, 0.014280724), (1, 0.01428148), (2, 0.014281982), (3, 0.01428059), (4, 0.014283068), (5, 0.014281249), (6, 0.014282262), (7, 0.014283687), (8, 0.8714636), (9, 0.014281378)]\n\n\nlabel id: 10\n\n\nlda result: [(0, 0.20578696), (2, 0.15337059), (4, 0.4799358), (5, 0.06033147), (8, 0.08129551)]\n\n\nlabel id: 18\n\n\nlda result: [(1, 0.10361827), (2, 0.05527945), (3, 0.7109083), (4, 0.049515486), (5, 0.010134702), (8, 0.012831275), (9, 0.05533035)]\n\n\nlabel id: 17\n\n\nlda result: [(0, 0.020029237), (1, 0.020024557), (2, 0.02002185), (3, 0.020023756), (4, 0.020019487), (5, 0.020024091), (6, 0.8197941), (7, 0.020018762), (8, 0.020019889), (9, 0.020024281)]\n\n\nlabel id: 34\n\n\nlda result: [(0, 0.116023876), (4, 0.6855978), (5, 0.083707646), (7, 0.1047039)]\n\n\nlabel id: 71\n\n\nlda result: [(3, 0.0557655), (5, 0.9378907)]\n\n\nlabel id: 104\n\n\nlda result: [(0, 0.065075), (1, 0.068911105), (3, 0.095410444), (4, 0.11538193), (9, 0.6486145)]\n\n\nlabel id: 49\n\n\nlda result: [(1, 0.06350381), (2, 0.038925216), (3, 0.66351616), (4, 0.043214), (5, 0.02859877), (6, 0.15489312)]\n\n\nlabel id: 17\n\n\nlda result: [(3, 0.5090968), (5, 0.23641588), (6, 0.2057999), (7, 0.03558733)]\n\n\n"
     ]
    }
   ],
   "source": [
    "# 测试10条\n",
    "for i in range(10):\n",
    "    print(\"label id:\", demo_labels[i])\n",
    "    print(\"\\n\")\n",
    "\n",
    "    doc_bow = dictionary.doc2bow(demo_sentences[i])    \n",
    "    rst = lda[doc_bow]\n",
    "    for idx, lky in rst\n",
    "    print(\"lda result:\", rst)\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}